<!-- part of the code adapted from reinforcejs -->

<!doctype html>
<html lang="en">
 <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Stock Prediction with Q Learning</title>
  <meta name="description" content="">
  <meta name="author" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- jquery and jqueryui -->
  <script src="https://code.jquery.com/jquery-2.1.3.min.js"></script>
  
  <!-- bootstrap -->
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
  <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">

  <!-- markdown -->
  <script type="text/javascript" src="{{ url_for('static', filename='external/marked.js') }}"></script>
  <script type="text/javascript" src="{{ url_for('static', filename='external/highlight.pack.js') }}"></script>
  <link rel="stylesheet" href="{{ url_for('static', filename='external/highlight_default.css') }}">
  <script>hljs.initHighlightingOnLoad();</script>
  
  <!-- GA -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-3698471-24', 'auto');
  ga('send', 'pageview');
  </script>

  <style>
  #wrap {
    width:800px;
    margin-left: auto;
    margin-right: auto;
  }
  </style>

  <script>
  function start() {
    $(".md").each(function(){
      $(this).html(marked($(this).html()));
    });
    renderJax();
  }
  var jaxrendered = false;
  function renderJax() {
    if(jaxrendered) { return; }
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
      jaxrendered = true;
    })();
  }
  </script>
 </head>
 <body onload="start();">

   <div id="wrap">
   
    <div id="mynav" style="border-bottom:1px solid #999; padding-bottom: 10px; margin-bottom:50px;">
        <div>
          <img src="{{ url_for('static', filename='img/loop.svg') }}" style="width:50px;height:50px;float:left;">
          <h1 style="font-size:50px;">Stock Prediction with <span style="color:#058;">Q-Learning</span></h1>
        </div>
        <ul class="menu">
            <li role="presentation"><a href="{{ url_for('about') }}">About</a></li>
          <li role="presentation"><a href="{{ url_for('learn') }}">Train Your Model</a></li>
        </ul>
        </div>

   <div id="exp" class="md">

  <div style="text-align:justify; margin: 20px; float:right; max-width:300px;">
      <img src="{{ url_for('static', filename='img/Q-table.png') }}" style="max-width:300px;"><br>
      Right: A sample Q-tabel trained with the stock of Google. <a href="{{ url_for('learn') }}">Train your own model</a>.
  </div>

### A bit of intrudoction and Setup

This is a simple online Q-learning application which allows you to train an auto-trading agent to make stock trading decision for you for a chosen stock.

- **State space**: There are 9x9 = 81 distinct states which represents the stock market.
The states are obtained by discretize the current adjusted closing price via compare it with the mean and standard deviation of a window of historical prices. 
The start state is the state of the first data we have scraped from <a href="https://finance.yahoo.com/">Yahoo! Finance</a>.

- **Actions**: The agent can choose two actions: *long* (1) or *short* (0). 
In the visualized grids, if a "long" action is predicted of greater confidence the arrow pointing upward would be longer.
Otherwise, if a "short" action is predicted of greater confidence the arrow pointing downward would be longer.

- **Rewards**: The agent receives reward when it perform an action in the market which is basically the modified profit.

### A simple introduction to Q-learning (if you are interested!)

The core idea is to estimate the action value function \\(Q^\pi(s,a)\\), which is the expected discounted reward obtained by the agent by taking action \\(a\\) in state \\(s\\) and then following some particular policy \\(\pi(a \\mid s)\\):

$$
Q^\pi (s,a) = E\_\pi \\{ r\_t + \\gamma r\_{t+1} + \\gamma^2 r\_{t+2} + \\ldots \\mid s\_t = s, a\_t = a \\}
$$

Where \\(s\\) is the current state of the agent, 
\\(a\\) is the action that the agent want to take at this state 
and \\(r\\) is the reward the agnet receives by taking this action.
A typical trajactory of (state, action, reward) looks like something below:

<div style="text-align:center; margin: 20px;">
<img src="{{ url_for('static', filename='img/sarsa.png') }}">
</div>

However, unlike a standard Machine Learning setting the agent picks the actions, and hence influences its own training set. Fun! The core idea is to notice that the Q function satisfies the Bellman equation, which is a recurrence relation that relates the Q function at one action node \\((s\_t, a\_t)\\) to the next one \\((s\_{t+1}, a\_{t+1})\\). In particular, looking at the above diagram the agent:

1. The agent picked some action \\(a\_t\\) in state \\(s\_t\\)
2. The environment responded with some reward \\(r\_t\\) and new state \\(s\_{t+1}\\)
3. The agent then picks some new action \\(a\_{t+1}\\) from its current policy \\(\pi\\).

The update function of **Q-Learning** is as follow:

$$
Q(s\_t, a\_t) \leftarrow Q(s\_t, a\_t) + \alpha \left[ r\_t + \gamma \max\_a Q(s\_{t+1}, a) - Q(s\_t, a\_t) \right]
$$

Basically we use dynamic programming and keep a table of Q-values and update it using the above algorithm and equantion.
There are many other details of this algorithm that might be too much to write in details here. 
e.g. priority queue in stead of purely random sampling and smooth Q function updates.
Interested user can read the source code and documentation in the repo (to be constructed).

 </body>
</html>